{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008cae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install albumentations\n",
    "# ! pip install --upgrade typing_extensions \n",
    "\n",
    "# ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "# tensorflow 2.4.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\n",
    "# tensorflow-gpu 2.4.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\n",
    "# Successfully installed typing_extensions-4.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096b08d",
   "metadata": {},
   "source": [
    "## generate augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4686787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "\n",
    "DIR_DATASET = '/home/young/hdd1'\n",
    "\n",
    "def load_imgpath(imagefilelist, category, n_sample=20):\n",
    "    img_names = []\n",
    "    with open(imagefilelist, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            data = line.strip().split(' ')\n",
    "            if int(data[1]) == d_name2idx[category]:\n",
    "                img_names.append(data[0])\n",
    "                \n",
    "    random.seed(1) #15\n",
    "    img_names = random.sample(img_names, n_sample)\n",
    "    img_names = [im.replace('/data/datasets', DIR_DATASET) for im in img_names]\n",
    "    return img_names\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def load_and_transform(img_names, category, expname, visualize=False, save_dir=None):\n",
    "    \n",
    "    orig_trans = A.Compose([\n",
    "                    A.Resize(height=256, width=256),\n",
    "                    A.CenterCrop(height=224, width=224),\n",
    "#                     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                    A.ToFloat(),\n",
    "                    ToTensorV2()])\n",
    "\n",
    "    if expname == 'exp_position':\n",
    "        tran_trans = A.Compose([\n",
    "                        A.Resize(height=256, width=256),\n",
    "                        A.CenterCrop(height=224, width=224),\n",
    "                        A.Affine(translate_percent=(-0.5,0.5),  p=1.0),\n",
    "    #                     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        A.ToFloat(), # if using normalize, float is not necessary\n",
    "                        ToTensorV2()])  \n",
    "        \n",
    "    elif expname == 'exp_size':\n",
    "\n",
    "        tran_trans = A.Compose([\n",
    "                        A.Resize(height=256, width=256),\n",
    "                        A.CenterCrop(height=224, width=224),\n",
    "                        A.Affine(scale=(0.5, 1.5),  p=1.0),\n",
    "    #                     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        A.ToFloat(), # if using normalize, float is not necessary\n",
    "                        ToTensorV2()])\n",
    "\n",
    "        \n",
    "        \n",
    "    elif expname == 'exp_stats':\n",
    "        \n",
    "        tran_trans = A.Compose([\n",
    "                        A.Resize(height=256, width=256),\n",
    "                        A.CenterCrop(height=224, width=224),\n",
    "                        A.Equalize(mode='cv', p=1.0),\n",
    "#                         A.ColorJitter(p=1.0),\n",
    "#                         A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        A.ToFloat(), # if using normalize, float is not necessary\n",
    "                        ToTensorV2()])  \n",
    "        \n",
    "    elif expname == 'exp_sf':     \n",
    "        tran_trans = A.Compose([\n",
    "                        A.Resize(height=256, width=256),\n",
    "                        A.CenterCrop(height=224, width=224),\n",
    "#                         A.Sharpen(p=1.0),\n",
    "                        A.Blur(blur_limit=3, p=1.0),\n",
    "    #                     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        A.ToFloat(), # if using normalize, float is not necessary\n",
    "                        ToTensorV2()])  \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    orig_imgs, trans_imgs =[], []\n",
    "    for img in img_names:\n",
    "        img = np.array(Image.open(img).convert('RGB'))\n",
    "        if img is None:\n",
    "            print(im_name)\n",
    "            \n",
    "        oimg = orig_trans(image=img)['image']\n",
    "        timg = tran_trans(image=img)['image']\n",
    "        \n",
    "        orig_imgs.append(oimg)\n",
    "        trans_imgs.append(timg)\n",
    "                \n",
    "            \n",
    "    if visualize:\n",
    "        for i, (oimg, timg) in enumerate(zip(orig_imgs, trans_imgs)):\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)    \n",
    "            ax1.imshow(oimg.cpu().numpy().transpose((1, 2, 0)))\n",
    "            ax2.imshow(timg.cpu().numpy().transpose((1, 2, 0)))\n",
    "            plt.show()\n",
    "\n",
    "    if save_dir is not None:\n",
    "\n",
    "        for i, (oimg, timg) in enumerate(zip(orig_imgs, trans_imgs)):\n",
    "            path_orig = os.path.join(save_dir, expname, f'{category}_orig', f'{category}_{i}.jpeg')\n",
    "            path_transform =os.path.join(save_dir, expname, f'{category}_tran', f'{category}_{i}.jpeg')\n",
    "\n",
    "            if not os.path.exists(os.path.dirname(path_orig)):\n",
    "                os.makedirs(os.path.dirname(path_orig))\n",
    "            if not os.path.exists(os.path.dirname(path_transform)):\n",
    "                os.makedirs(os.path.dirname(path_transform))\n",
    "            \n",
    "            save_image(oimg, path_orig)\n",
    "            save_image(timg, path_transform)\n",
    "        print('images saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b071343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elephant\n",
      "images saved to disk\n",
      "chair\n",
      "images saved to disk\n",
      "bicycle\n",
      "images saved to disk\n",
      "car\n",
      "images saved to disk\n",
      "bird\n",
      "images saved to disk\n",
      "truck\n",
      "images saved to disk\n",
      "dog\n",
      "images saved to disk\n",
      "boat\n",
      "images saved to disk\n",
      "keyboard\n",
      "images saved to disk\n",
      "bottle\n",
      "images saved to disk\n",
      "cat\n",
      "images saved to disk\n",
      "knife\n",
      "images saved to disk\n",
      "airplane\n",
      "images saved to disk\n",
      "clock\n",
      "images saved to disk\n",
      "bear\n",
      "images saved to disk\n",
      "oven\n",
      "images saved to disk\n",
      "elephant\n",
      "images saved to disk\n",
      "chair\n",
      "images saved to disk\n",
      "bicycle\n",
      "images saved to disk\n",
      "car\n",
      "images saved to disk\n",
      "bird\n",
      "images saved to disk\n",
      "truck\n",
      "images saved to disk\n",
      "dog\n",
      "images saved to disk\n",
      "boat\n",
      "images saved to disk\n",
      "keyboard\n",
      "images saved to disk\n",
      "bottle\n",
      "images saved to disk\n",
      "cat\n",
      "images saved to disk\n",
      "knife\n",
      "images saved to disk\n",
      "airplane\n",
      "images saved to disk\n",
      "clock\n",
      "images saved to disk\n",
      "bear\n",
      "images saved to disk\n",
      "oven\n",
      "images saved to disk\n",
      "elephant\n",
      "images saved to disk\n",
      "chair\n",
      "images saved to disk\n",
      "bicycle\n",
      "images saved to disk\n",
      "car\n",
      "images saved to disk\n",
      "bird\n",
      "images saved to disk\n",
      "truck\n",
      "images saved to disk\n",
      "dog\n",
      "images saved to disk\n",
      "boat\n",
      "images saved to disk\n",
      "keyboard\n",
      "images saved to disk\n",
      "bottle\n",
      "images saved to disk\n",
      "cat\n",
      "images saved to disk\n",
      "knife\n",
      "images saved to disk\n",
      "airplane\n",
      "images saved to disk\n",
      "clock\n",
      "images saved to disk\n",
      "bear\n",
      "images saved to disk\n",
      "oven\n",
      "images saved to disk\n",
      "elephant\n",
      "images saved to disk\n",
      "chair\n",
      "images saved to disk\n",
      "bicycle\n",
      "images saved to disk\n",
      "car\n",
      "images saved to disk\n",
      "bird\n",
      "images saved to disk\n",
      "truck\n",
      "images saved to disk\n",
      "dog\n",
      "images saved to disk\n",
      "boat\n",
      "images saved to disk\n",
      "keyboard\n",
      "images saved to disk\n",
      "bottle\n",
      "images saved to disk\n",
      "cat\n",
      "images saved to disk\n",
      "knife\n",
      "images saved to disk\n",
      "airplane\n",
      "images saved to disk\n",
      "clock\n",
      "images saved to disk\n",
      "bear\n",
      "images saved to disk\n",
      "oven\n",
      "images saved to disk\n"
     ]
    }
   ],
   "source": [
    "# generate images\n",
    "imagefilelist = './data/imagenet-16/imagenet-16-val_list.txt'\n",
    "# expname = 'exp_size' #'exp_position', 'exp_size', 'exp_stats'\n",
    "for expname in ['exp_size', 'exp_position', 'exp_stats', 'exp_sf']:\n",
    "    for category in d_name2idx.keys():\n",
    "        print(category)\n",
    "        img_names = load_imgpath(imagefilelist, category)\n",
    "        load_and_transform(img_names, category, expname, visualize=False, save_dir='./data/imagenet-16/') \n",
    "    #     load_and_transform(img_names, category, expname, visualize=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49266bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lists were generated\n"
     ]
    }
   ],
   "source": [
    "# generate datasource\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "DIR_DATASOURCE= './data/imagenet-16'\n",
    "    \n",
    "for expname in ['exp_position', 'exp_sf', 'exp_size', 'exp_stats']:\n",
    "    \n",
    "    FILENAME = 'imagenet-16-val-aug'\n",
    "    forig = open(os.path.join(DIR_DATASOURCE, FILENAME + '_'+ expname +'_original_list.txt'), 'w')\n",
    "    ftran = open(os.path.join(DIR_DATASOURCE, FILENAME + '_'+ expname +'_transform_list.txt'), 'w')\n",
    "\n",
    "    exp_folder = os.path.join(DIR_DATASOURCE, expname)\n",
    "    folders = os.listdir(exp_folder)\n",
    "    for i, folder in enumerate(folders):\n",
    "        folder_path = os.path.join(exp_folder, folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        if folder.split('_')[1] == 'orig':\n",
    "            for file in files:\n",
    "                forig.write('{} {}\\n'.format(os.path.join(folder_path, file), folder.split('_')[0]))\n",
    "        if folder.split('_')[1] == 'tran':\n",
    "            for file in files:\n",
    "                ftran.write('{} {}\\n'.format(os.path.join(folder_path, file), folder.split('_')[0]))\n",
    "                \n",
    "    forig.close()\n",
    "    ftran.close()\n",
    "    \n",
    "print('lists were generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modelvshuman]",
   "language": "python",
   "name": "conda-env-modelvshuman-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
